#include "DetectWithOF3.h"


DetectWithOF3::DetectWithOF3(KVConfig *cfg)
	: Detect(cfg)
{
	fb_pyrscale_ = atof(cfg_->get_value("fb_pyrscale", "0.5"));
	fb_levels_ = atoi(cfg_->get_value("fb_levels", "2"));
	fb_winsize_ = atoi(cfg_->get_value("fb_winsize", "13"));
	fb_iters_ = atoi(cfg_->get_value("fb_iters", "1"));
	fb_polyn_ = atoi(cfg_->get_value("fb_polyn", "5"));
	fb_polysigma_ = atof(cfg_->get_value("fb_polysigma", "1.1"));

	of_.flags = 0;
	of_.pyrScale = fb_pyrscale_;
	of_.numLevels = fb_levels_;
	of_.winSize = fb_winsize_;
	of_.numIters = fb_iters_;
	of_.polyN = fb_polyn_;
	of_.polySigma = fb_polysigma_;

	d_gray_prev_ = cv::ocl::oclMat(video_height_, video_width_, CV_8UC1);
	d_gray_curr_ = d_gray_prev_.clone();
	d_first_ = true;

	threshold_optical_flow_ = atof(cfg_->get_value("of3_threshold", "2.2"));

	int ker_erode = atoi(cfg_->get_value("ker_erode", "5"));
	int ker_dilate = atoi(cfg_->get_value("ker_dilate", "15"));

	ker_erode_ = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(ker_erode, ker_erode));
	ker_dilate_ = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(ker_dilate, ker_dilate));

	up_angle_ = atoi(cfg_->get_value("up_angle", "110"));

	area_max_ = atof(cfg_->get_value("of3_area_max", "2800"));
	area_min_ = atof(cfg_->get_value("of3_area_min", "400"));
	area_bottom_max_ = atof(cfg_->get_value("of_area_bottom_max", "4500"));
	area_bottom_min_ = atof(cfg_->get_value("of_area_bottom_min", "2500"));
	area_bottom_y_ = atof(cfg_->get_value("of_area_bottom_y", "0.6667"));

	delay_ = atof(cfg_->get_value("of3_delay", "0.3"));

	debug_lmax_ = 0, debug_lmin_ = 10000;
	debug_max_dis_ = .0;

	merge_mode_ = atoi(cfg_->get_value("of3_merge_mode", "1"));

	//if (area_max_rect_.width > 0 && area_min_rect_.width > 0) {
	//	// y = ax + b
	//	//	 a = (y2-y1)/(x2-x1)
	//	//	 b = (x1y2 - x2y1)/(x1-x2)
	//	//
	//	area_factor_ab_[0] = (area_max_rect_.area() - area_min_rect_.area()) / (CENTER_Y(area_max_rect_) - CENTER_Y(area_min_rect_));
	//	area_factor_ab_[1] = (CENTER_Y(area_min_rect_) * area_max_rect_.area() - (CENTER_Y(area_max_rect_) * area_min_rect_.area())) /
	//		(CENTER_Y(area_min_rect_) - CENTER_Y(area_max_rect_));
	//}

	log("%s: starting...\n", __FUNCTION__);
	log("\tker for erode is %d, for dilate is %d\n", ker_erode, ker_dilate);
	log("\tof3_threadhold: %f\n", threshold_optical_flow_);
	log("\tup_angle: %d\n", up_angle_);
	log("\tof3_area_max: %d\n", area_max_);
	log("\tof3_area_min: %d\n", area_min_);
	log("\tof3_delay: %f\n", delay_);
	log("\tof3_merge_mode: %d\n", merge_mode_);
	log("\tarea_factor_ab: %.3f, %.3f\n", area_factor_ab_[0], area_factor_ab_[1]);
	log("\tarea_min, area_max: %.0f, %.0f\n", area_min_, area_max_);
	log("\tarea_bottom_min, area_bottom_max, area_bottom_y: %.0f, %.0f, %.4f\n", area_bottom_min_, area_bottom_max_, area_bottom_y_);
	log("\n");
}

DetectWithOF3::~DetectWithOF3(void)
{
}

void DetectWithOF3::calc_optical_flow(const cv::Mat &p0, const cv::Mat &p1, cv::Mat &dis, cv::Mat &ang, cv::Mat &dx, cv::Mat &dy)
{
	if (d_first_) {
		d_first_ = false;
		d_gray_prev_.upload(p0);
		cv::Mat zero = cv::Mat::zeros(p0.rows, p0.cols, CV_32F);
		d_dx_.upload(zero), d_dy_.upload(zero);
	}
	else {
		d_gray_curr_.upload(p1);
		of_(d_gray_prev_, d_gray_curr_, d_dx_, d_dy_);
		cv::ocl::swap(d_gray_prev_, d_gray_curr_);
	}

	d_dx_.download(dx), d_dy_.download(dy);	// 目前没有用到 ..

	cv::ocl::cartToPolar(d_dx_, d_dy_, d_distance_, d_angle_, true);
	d_distance_.download(dis), d_angle_.download(ang);
}

void DetectWithOF3::merge_targets()
{
	/** TODO：有可能需要合并临近的 targets_，比如一个人站立时，可能头部有个活动，手部也有活动，但都是小范围的，会被作为两个 Target ...
	 */

}

static cv::Rect _outer_of_rcs(const std::deque<cv::Rect> &rcs)
{
	assert(rcs.size() > 0);

	cv::Rect rc = rcs.front();
	for (size_t i = 1; i < rcs.size(); i++) {
		rc |= rcs[i];
	}

	return rc;
}

void DetectWithOF3::merge_targets(const std::vector<cv::Rect> &motion_rcs, const std::vector<int> &dirs,
								  const std::vector<DetectWithOF3::DirCnt> &dircnts, const cv::Mat &dx, const cv::Mat &dy)
{
	/** 活动区域需要与历史活动区域进行合并，有两种合并方式：
			1. 合并最后的矩形：这样貌似更合理，但有可能导致一个人形成多个目标 ...
			2. 合并到最大矩形：但这样有可能会得到更多的误差 ...
	 */

	int merge_mode = merge_mode_;	//

	assert(motion_rcs.size() == dirs.size());

	for (size_t i = 0; i < motion_rcs.size(); i++) {
		Dir dir = (Dir)dirs[i];
		cv::Rect mrc = motion_rcs[i];

		double amin, amax;
		bool bottom = calc_area(mrc.y+mrc.height, amin, amax);

		if (mrc.area() > amax) {
			log("WARNING: %s: tooooooo large motion rect: [%d,%d, %d-%d], bottom=%d, area=%d, max=%.0f\n", __FUNCTION__,
				mrc.x, mrc.y, mrc.width, mrc.height,
				bottom, mrc.area(), amax);
			continue;
		}

		bool merged = false;
		for (TARGETS::iterator it = targets_.begin(); it != targets_.end(); ++it) {
			cv::Rect to_merge = merge_mode == 1 ? it->hist_rcs.back() : it->rc;

			if (is_cross(mrc, to_merge)) {
				// 最多保存历史 10帧即可 ...
				while (it->hist_dirs.size() >= 10) {
					it->hist_dirs.pop_front();
					it->hist_dir_cnt.pop_front();
					it->hist_of_dx.pop_front();
					it->hist_of_dy.pop_front();
					it->hist_rcs.pop_front();
					it->rc = _outer_of_rcs(it->hist_rcs);

				}

				it->hist_rcs.push_back(motion_rcs[i]);
				it->hist_dirs.push_back(dir);
				it->hist_dir_cnt.push_back(dircnts[i]);
				it->hist_of_dx.push_back(dx(motion_rcs[i]));
				it->hist_of_dy.push_back(dy(motion_rcs[i]));
				it->rc |= motion_rcs[i];	// 合并外接矩形
				it->stamp_last = curr_stamp_;

				// 如果target.rc超大，则仅仅保留最后几帧的历史
				while (it->rc.area() > area_max_ && it->hist_rcs.size() > 1) {
					it->hist_dirs.pop_front();
					it->hist_dir_cnt.pop_front();
					it->hist_of_dx.pop_front();
					it->hist_of_dy.pop_front();
					it->hist_rcs.pop_front();

					it->rc = _outer_of_rcs(it->hist_rcs);
				}

				merged = true;
			}
		}

		if (!merged) {
			// 新的 targets
			Target t;
			t.stamp_last = t.stamp_first = curr_stamp_;
			t.rc = motion_rcs[i];
			t.hist_rcs.push_back(motion_rcs[i]);
			t.hist_dirs.push_back(dir);
			t.hist_dir_cnt.push_back(dircnts[i]);
			t.hist_of_dx.push_back(dx(motion_rcs[i]));
			t.hist_of_dy.push_back(dy(motion_rcs[i]));

			targets_.push_back(t);
		}
	}
}

std::vector<cv::Rect> DetectWithOF3::detect0(size_t cnt, cv::Mat &origin, cv::Mat &gray_prev, cv::Mat &gray_curr, cv::vector<int> &dirs)
{
	std::vector<cv::Rect> rcs;
	dirs.clear();

	// 计算稠密光流
	cv::Mat distance, angle;
	cv::Mat dx, dy;
	calc_optical_flow(gray_prev, gray_curr, distance, angle, dx, dy);

	if (debug_) {
		show_optical_flow(origin, distance, angle);

		int yy = origin.rows * area_bottom_y_;
		cv::line(origin, cv::Point(0, yy), cv::Point(origin.cols-1, yy), cv::Scalar(255, 0, 0));
	}

	// 得到运动区域，每个区域的总体方向，每个运动区域中各方向的统计数
	std::vector<cv::Rect> motion_rects;
	std::vector<int> motion_dirs;
	std::vector<DirCnt> motion_dircnts;
	get_motion_rects(distance, angle, motion_rects, motion_dirs, motion_dircnts);

	// 合并运动区域和已存在的目标 ...
	merge_targets(motion_rects, motion_dirs, motion_dircnts, dx, dy);

	// 合并 targets
	merge_targets();

	// 分析每个目标的行为 ..
	for (TARGETS::iterator it = targets_.begin(); it != targets_.end(); ) {
		if (debug_) {
			cv::rectangle(origin, it->rc, cv::Scalar(0, 255, 255));
		}

		if (curr_stamp_ - it->stamp_last >= delay_) {				//
			/** XXX: 如果一个位置超过一段时间而没有更新，则说明这个位置的目标已经停止动作了，此时分析这段时间内，目标做了什么....
					 但这样只能等动作完成后一段时间才能判断了，又增加了段延迟 ...
			 */
			log("TARGET: [%d,%d -- %d,%d]: %u motions\n", it->rc.x, it->rc.y, it->rc.width, it->rc.height, it->hist_rcs.size());
			for (size_t i = 0; i < it->hist_rcs.size(); i++) {
				log("\t%s: %d, l=%d[%.0f], r=%d[%.0f], u=%d[%.0f], d=%d[%.0f]\n",
					DirDesc[it->hist_dirs[i]], it->hist_rcs[i].area(),
					it->hist_dir_cnt[i].left, it->hist_dir_cnt[i].dis_left,
					it->hist_dir_cnt[i].right, it->hist_dir_cnt[i].dis_right,
					it->hist_dir_cnt[i].up, it->hist_dir_cnt[i].dis_up,
					it->hist_dir_cnt[i].down, it->hist_dir_cnt[i].dis_down);
			}

			Dir dir;
			cv::Rect rc;
			if (analyze_target_hist(*it, dir, rc)) {
				// 可以确认的行为 ...
				log("Save Target: dir=%s, rc=[%d,%d,  %d-%d]，area=%d, bottom=%d\n",
					DirDesc[dir], rc.x, rc.y, rc.width, rc.height, rc.area(), rc.y+rc.height);

				dirs.push_back(dir);
				rcs.push_back(rc);
			}

			it = targets_.erase(it);
		}
		else {
			// TODO: 中间片段的分析 ???

			// 继续 ...
			++it;
		}
	}

	return rcs;
}

static void _draw_line(cv::Mat &origin, const cv::Point &from, float dis, float ang)
{
	ang = (360 - ang) * M_PI / 180;
	cv::Point to(from.x + dis*cos(ang), from.y - dis*sin(ang));
	cv::line(origin, from, to, cv::Scalar(0, 255, 0));
	cv::circle(origin, from, 1, cv::Scalar(0, 0, 255), 1);
}

void DetectWithOF3::show_optical_flow(cv::Mat &origin, const cv::Mat &dis, const cv::Mat &ang)
{
	int xstep = 4, ystep = 4;
	for (int y = 0; y < dis.rows; y+=ystep) {
		const float *pd = dis.ptr<float>(y), *pa = ang.ptr<float>(y);
		for (int x = 0; x < dis.cols; x+=xstep) {
			if (pd[x] >= threshold_optical_flow_) {
				_draw_line(origin, cv::Point(x, y), pd[x], pa[x]);
			}
		}
	}
}

void DetectWithOF3::get_motion_rects(const cv::Mat &dis, const cv::Mat &ang, std::vector<cv::Rect> &rcs, std::vector<int> &dirs,
									 std::vector<DetectWithOF3::DirCnt> &dircnts)
{
	rcs.clear(), dirs.clear(), dircnts.clear();

	cv::Mat distance;  // 直接 32F 转换 8U，不进行拉伸，因为 255 足够了 ..
	dis.convertTo(distance, CV_8U);

	cv::threshold(distance, distance, threshold_optical_flow_, 255, cv::THRESH_BINARY);

	cv::erode(distance, distance, ker_erode_);
	cv::dilate(distance, distance, ker_dilate_);

	std::vector<std::vector<cv::Point> > contours;
	cv::findContours(distance, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_NONE);

	for (std::vector<std::vector<cv::Point> >::const_iterator it = contours.begin(); it != contours.end(); ++it) {
		cv::Rect brc = cv::boundingRect(*it);
		rcs.push_back(brc);	// 小活动都加入累计，在最后进行分割

		// FIXME: 计算这个rect中的方向，依次统计四个方向，注意，这里选取 brc 的上半部分计算方向，上部分应该是头部，方向会比较正确
		cv::Rect roi = brc;
		roi.height = roi.height;
		DirCnt dc;
		Dir dir = get_roi_property(roi, dis, distance, ang, dc);
		dirs.push_back(dir);
		dircnts.push_back(dc);

		if (debug_) {
			cv::putText(origin_, DirDesc[dir], brc.tl(), cv::FONT_HERSHEY_PLAIN, 1.0, cv::Scalar(255, 255, 255), 2);
		}
	}
}

Dir DetectWithOF3::get_roi_property(const cv::Rect &roi, const cv::Mat &dis, const cv::Mat &dis_bin, const cv::Mat &ang, DirCnt &dc)
{
	// 在 roi 中，取出每个方向的统计点数，注意 dis_bin 为二值，方便计算
	int dirs[4] = { 0, 0, 0, 0 };
	double diss[4] = { 0.0, 0.0, 0.0, 0.0 };

	cv::Mat rd = dis_bin(roi), ra = ang(roi), rdis = dis(roi);
	for (int y = 0; y < rd.rows; y++) {
		unsigned char *prd = rd.ptr<unsigned char>(y);
		float *pra = ra.ptr<float>(y);
		float *pdis = rdis.ptr<float>(y);
		for (int x = 0; x < rd.cols; x++) {
			if (prd[x]) {
				Dir d = ang2dir(pra[x]);
				dirs[d]++;			// 方向统计
				diss[d] += pdis[x];	// 距离累加
			}
		}
	}

	dc.left = dirs[LEFT], dc.dis_left = diss[LEFT];
	dc.right = dirs[RIGHT], dc.dis_right = diss[RIGHT];
	dc.up = dirs[UP], dc.dis_up = diss[UP];
	dc.down = dirs[DOWN], dc.dis_down = diss[DOWN];

	Dir dir = LEFT;
	int d = dc.left;
	if (d < dc.right) {
		d = dc.right;
		dir = RIGHT;
	}
	if (d < dc.up) {
		d = dc.up;
		dir = UP;
	}
	if (d < dc.down) {
		d = dc.down;
		dir = DOWN;
	}

	return dir;
}

Dir DetectWithOF3::ang2dir(float ang) const
{
	// 根据角度，返回方向
	int up_half = up_angle_ / 2;
	int up_min = 270 - up_half, up_max = 270 + up_half;
	if (ang >= up_min && ang <= up_max) {
		return UP;
	}
	else if (ang >= 45 && ang <= 135) {
		return DOWN;
	}
	else if (ang > 135 && ang < up_min) {
		return LEFT;
	}
	else {
		return RIGHT;
	}
}

bool DetectWithOF3::calc_area(int y, double &area_min, double &area_max) const
{
	/* 根据 area_max_rect_, area_min_rect_ 使用线性计算 y 位置，大约的 area 值

		使用最大最小框的中心的y轴，做线性变化
	 */
	//return area_factor_ab_[0] * y + area_factor_ab_[1];

	/** FIXME: 但光流变化的往往不是很准确，有时候后排的也不比前排的小

			从测试看，只有最靠近前排，面积比较夸张，中后排基本还在 (500, 3500) 的范围内吧，最前排使用 (3500, 6000)
	 */
	if (y < origin_.rows * area_bottom_y_) {
		area_min = area_min_;
		area_max = area_max_;
		return false;
	}
	else {
		area_min = area_bottom_min_;
		area_max = area_bottom_max_;
		return true;
	}
}

bool DetectWithOF3::analyze_target_hist(const DetectWithOF3::Target &target, Dir &dir, cv::Rect &rc) const
{
	bool confirmed = false;

	/** 根据 target 中的一段活动历史，分析是否为“坐”，“站”，“左走”，“右走” 四种有效行为，或者无法判断的行为 ...

		target.hist_rc: 历史目标位置
		target.hist_dir: 每个位置的主方向
		target.hist_dir_cnt: 每个方向的统计，

	 */

	// 如果 tareget.rc 很大，说明是较大范围的活动，扔掉
	double amin, amax;
	bool bottom = calc_area(target.rc.y+target.rc.height, amin, amax);

	if (target.rc.area() > amax) {
		log("%s: Tooooo Large motion range: rc=[%d,%d,   %d,%d], area=%d, max area=%.0f, bottom=%d\n", __FUNCTION__,
			target.rc.x, target.rc.y, target.rc.width, target.rc.height, target.rc.area(), amax, bottom);
		for (size_t i = 0; i < target.hist_dirs.size(); i++) {
			log("\t#%d: %s, [%d,%d,  %d,%d]\n", i, DirDesc[target.hist_dirs[i]],
				target.hist_rcs[i].x, target.hist_rcs[i].y, target.hist_rcs[i].width, target.hist_rcs[i].height);
		}
		return false;
	}
	else if (target.rc.area() < amin) {
		log("%s: Tooooo Small motion range: rc=[%d,%d,  %d,%d], area=%d, want_area=%.0f, bottom=%d\n", __FUNCTION__,
			target.rc.x, target.rc.y, target.rc.width, target.rc.height, target.rc.area(), amin, bottom);
		for (size_t i = 0; i < target.hist_dirs.size(); i++) {
			log("\t#%d: %s, [%d,%d,  %d,%d]\n", i, DirDesc[target.hist_dirs[i]],
				target.hist_rcs[i].x, target.hist_rcs[i].y, target.hist_rcs[i].width, target.hist_rcs[i].height);
		}
		return false;
	}

	//
	double sleft = 0.0, sright = 0.0, sup = 0.0, sdown = 0.0;
	for (size_t i = 0; i < target.hist_dir_cnt.size(); i++) {
		sleft += target.hist_dir_cnt[i].dis_left;
		sright += target.hist_dir_cnt[i].dis_right;
		sup += target.hist_dir_cnt[i].dis_up;
		sdown += target.hist_dir_cnt[i].dis_down;
	}

	//fprintf(stderr, "---- left=%.0f, right=%.0f, up=%.0f, down=%.0f\n", sleft, sright, sup, sdown);

	// 直接返回最大的方向？
	double r = 0.0;
	if (r < sleft) {
		dir = LEFT;
		r = sleft;
	}

	if (r < sright) {
		dir = RIGHT;
		r = sright;
	}

	if (r < sup) {
		dir = UP;
		r = sup;
	}

	if (r < sdown) {
		dir = DOWN;
		r = sdown;
	}

	rc = target.rc;

	confirmed = true;

	return confirmed;
}
