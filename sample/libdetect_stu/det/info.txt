DetectWithOF5:

	2015/11/5:
		增加稠密光流，在Motion范围内做稠密光流，算法如下：
			1. 针对一个motion计算；
			2. 保留7帧稠密光流的x，y方向；
			3. 计算这7帧x,y的矢量和；
			4. 转换为极坐标，x轴方向为0，顺时针旋转，正上方110°夹角认为是向上 ..
				右：[325 .. 360, 0..45]
				下：[45 .. 135 ]
				左：[135 .. 215]
				上：[215 .. 325]
			对距离归一化(0 .. 1.0)，然后去阈值 0.3
			对角度归一化，右=0，下=90，左=180，上=270，
			然后画出hsv图。
			
		本来希望能根据一个motion中稠密光流的方向的点的个数来判断，但看起来不灵 :(
		

	2015/11/3:
         1. 从diff中找轮廓；
         2. 求所有轮廓的最小外接圆，并根据半径从大到小排序
         3. 从大到小检查是否需要合并：
                3.1. 如果两个圆相交则合并小圆到大圆；
                3.2 如果两个圆的半径差的比较大时，并且两个圆心之间距离小于大圆半径的1.5倍，则合并小圆到大圆中；  （以上三步已经实现，看 222.mp4 能够较好的合并老师身上的零散轮廓）
         4. 将合并后的轮廓再与估算目标大小比较 .... 
		 5. 根据轮廓位置删除小于理论大小 0.1 倍的轮廓 
	跑的效果在 images 目录中；


	2015/10/28：
		针对昨天的“motion”重叠，增加了 merge_overlapped_motions()，在 merge_motions() 中调用，
		merge_overlapped_motions:
			如果两个motions最后的两个历史轮廓完全相同，则认为这两个motion是一个。
		现在motion比较干净了；
		今天开始重新训练今天开始重新训练 22x22 的“头肩库”，看看能不能提高准确率；（预计的跑两天）
	
	2015/10/27:
		修改算法：
			现在既然使用较大图像，估计头肩/脸的探测准确率应该能提高（需要重新训练库）。
			
			1. 	使用上个版本的“活动区域”概念，创建Motion后，调用init_tracking()查找“脸”，如果找不到，在后面
				继续找，找到“脸”后，在“脸”处找30个角点用于跟踪；（Motion::tracking_pts 中保存角点的轨迹历史）
			2.	tracking_motions(): 使用稀疏光流对每个 Motion 中的点进行跟踪，失败的点，设置为 (-1, -1).
			3.  draw_tracking(): 画出跟踪点的运动轨迹 ...
			4.	根据Motion的轨迹，判断Motion的动作？（未实现）
			
		从对 222.mp4 的测试看，对于小范围的活动，如果找到“脸”，能明显看出“轨迹”，但对较大范围的活动，Motion 找的
		不好，出现大量重叠 ...
			

	2015/10/24：
	新增实现，将代码覆盖，然后修改 runtime/bin/student_detect_trace.config.session 中的 a_mode=5 即可；

   1. save_hist(): 保存N帧历史的gray和diff；

   2. find_motions(): 根据 diff 查找“活动区域”；
		2.1 threshold(diff): 对diff应用阈值，现在设置为 30
		2.2 findContours(): 找外轮廓；
		2.3 merge_contours(): 合并轮廓；
			2.3.1 minClosingCircle(): 每个轮廓的最小外界圆；
			2.3.2 合并所有外接圆“相交”的轮廓的点，然后利用这些点找外接凸边形，该凸边形作为合并后的轮廓；
			2.3.3 删除面积很小的合并轮廓；
			2.3.4 用新的轮廓构造“活动区域”

   3. “活动区域”：对应 DetectWithOF5::Motion 类：描述了一段时间内，一个可能的目标的连续活动；
		3.1 从2中得到“活动区域”；
		3.2 活动区域记录轮廓的连续位置； Motion::history
		3.3 当新的轮廓与活动区域历史中最后一个轮廓“相交”时，就认为新的轮廓属于这个活动区域；（FIXME）
		3.4 当超过300毫秒，没有“相交”轮廓时，则认为活动区域超时；
			3.4.1 此时似乎可以根据 history 的位置，大体推断这个motion的活动轨迹；（未实现）
			3.4.2 也可以根据从 save_hist() 的 gray 中，计算整个活动区域内每帧的光流；（未实现）
			3.4.3 也可以搜索每帧的“头肩”；（代码中已经实现，但发现有漏检，有时候检测到其他人了，反而会影响轨迹判断）
